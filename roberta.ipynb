{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### hyperparameters #####\n",
    "\n",
    "MODEL = 'microsoft/deberta-base'\n",
    "MODEL_SAVE_PATH = 'deberta-base'\n",
    "FAST_TOKENIZER = True\n",
    "PADDING = True\n",
    "TRUNCATION = True\n",
    "BATCH_SIZE = 4\n",
    "WARMUP = 600\n",
    "WEIGHT_DECAY = 0.1\n",
    "LEARNING_RATE = 1.478e-5\n",
    "TRAIN_EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification, DebertaTokenizerFast\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from dont_patronize_me import DontPatronizeMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up...\n",
      "Cleanup done!\n"
     ]
    }
   ],
   "source": [
    "##### cleanup #####\n",
    "print(\"Cleaning up...\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"Cleanup done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCLDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(model, fast=True):\n",
    "\n",
    "    print(\"Preparing model...\")\n",
    "\n",
    "    if fast:\n",
    "        tokenizer = DebertaTokenizerFast.from_pretrained(model)\n",
    "    else:\n",
    "        tokenizer = DebertaTokenizer.from_pretrained(model)\n",
    "\n",
    "    model = DebertaForSequenceClassification.from_pretrained(model)\n",
    "\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    print(\"Model prepared!\")\n",
    "\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset_from_csv(tokenizer):\n",
    "\n",
    "    # training data set comes from csv file, dev set from official dev set\n",
    "    # test set from official test set\n",
    "    print(\"Loading datasets...\")\n",
    "\n",
    "    dpm = DontPatronizeMe('.', '.')\n",
    "    dpm.load_task1()\n",
    "\n",
    "    # get dev set\n",
    "    deids = pd.read_csv('dev_semeval_parids-labels.csv')\n",
    "    deids.par_id = deids.par_id.astype(str)\n",
    "\n",
    "    rows = [] # will contain par_id, label and text\n",
    "    for idx in range(len(deids)):\n",
    "        parid = deids.par_id[idx]\n",
    "        # select row from original dataset\n",
    "        text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n",
    "        label = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].label.values[0]\n",
    "        rows.append({\n",
    "            'par_id':parid,\n",
    "            'text':text,\n",
    "            'label':label\n",
    "        })\n",
    "\n",
    "    dedf1 = pd.DataFrame(rows)\n",
    "\n",
    "    # get train set\n",
    "    trdf1 = pd.read_csv('augmented_data_upsampled_factor_10.csv', sep='\\t')\n",
    "\n",
    "    # add keyword to the training data set\n",
    "    trdf1['text'] = trdf1[['keyword', 'text']].agg(' '.join, axis=1)\n",
    "\n",
    "    # convert to int, error otherwise\n",
    "    trdf1['label'] = pd.to_numeric(trdf1['label'], errors='coerce')\n",
    "\n",
    "    # shuffle only training dataset\n",
    "    trdf1 = trdf1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # get test set\n",
    "    tedf1 = pd.read_csv('task4_test.tsv', sep='\\t', names=['id1', 'id2', 'keyword', 'loc', 'text'])\n",
    "\n",
    "    # add keyword to the test data set\n",
    "    tedf1['text'] = tedf1[['keyword', 'text']].agg(' '.join, axis=1)\n",
    "\n",
    "    # convert to numpy\n",
    "    trdf1 = trdf1.to_numpy()\n",
    "    dedf1 = dedf1.to_numpy()\n",
    "    tedf1 = tedf1.to_numpy()\n",
    "\n",
    "    # posts and labels: data currently organised as (par_id | text | label) for dev set\n",
    "    #                                               (text | label | keyword) for augmented training set\n",
    "    #                                               (id1 | id2 | keyword | loc | text) for test set\n",
    "\n",
    "    trposts = [row[0] for row in trdf1]\n",
    "    trlabels = [row[1] for row in trdf1]\n",
    "    deposts = [row[1] for row in dedf1]\n",
    "    delabels = [row[2] for row in dedf1]\n",
    "    teposts = [row[4] for row in tedf1]\n",
    "    telabels = []\n",
    "\n",
    "    # perform encoding\n",
    "    encodings_trn = tokenizer(trposts, padding=PADDING, truncation=TRUNCATION)\n",
    "    encodings_dev = tokenizer(deposts, padding=PADDING, truncation=TRUNCATION)\n",
    "    encodings_tst = tokenizer(teposts, padding=PADDING, truncation=TRUNCATION)\n",
    "\n",
    "    # convert to Dataset\n",
    "    dataset_trn = PCLDataset(encodings_trn, trlabels)\n",
    "    dataset_dev = PCLDataset(encodings_dev, delabels)\n",
    "    dataset_tst = PCLDataset(encodings_tst, telabels)\n",
    "\n",
    "    print(\"Datasets loaded!\")\n",
    "\n",
    "    return dataset_trn, dataset_dev, dataset_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(tokenizer):\n",
    "\n",
    "    # both training and test data sets come from official data\n",
    "    print(\"Loading datasets...\")\n",
    "\n",
    "    dpm = DontPatronizeMe('.', '.')\n",
    "    dpm.load_task1()\n",
    "\n",
    "    trids = pd.read_csv('train_semeval_parids-labels.csv')\n",
    "    teids = pd.read_csv('dev_semeval_parids-labels.csv')\n",
    "    trids.par_id = trids.par_id.astype(str)\n",
    "    teids.par_id = teids.par_id.astype(str)\n",
    "\n",
    "    rows = [] # will contain par_id, label and text\n",
    "    for idx in range(len(trids)):\n",
    "        parid = trids.par_id[idx]\n",
    "        # select row from original dataset to retrieve `text` and binary label\n",
    "        text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n",
    "        label = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].label.values[0]\n",
    "        rows.append({\n",
    "            'par_id':parid,\n",
    "            'text':text,\n",
    "            'label':label\n",
    "        })\n",
    "\n",
    "    trdf1 = pd.DataFrame(rows)\n",
    "\n",
    "    rows = [] # will contain par_id, label and text\n",
    "    for idx in range(len(teids)):\n",
    "        parid = teids.par_id[idx]\n",
    "        # select row from original dataset\n",
    "        text = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].text.values[0]\n",
    "        label = dpm.train_task1_df.loc[dpm.train_task1_df.par_id == parid].label.values[0]\n",
    "        rows.append({\n",
    "            'par_id':parid,\n",
    "            'text':text,\n",
    "            'label':label\n",
    "        })\n",
    "\n",
    "    tedf1 = pd.DataFrame(rows)\n",
    "\n",
    "    if UPSAMPLE and UPSAMPLE_FACTOR > 1:\n",
    "        upsampled_tr = trdf1\n",
    "        for _ in range(UPSAMPLE_FACTOR - 1):\n",
    "            upsampled_tr = upsampled_tr.append(trdf1.loc[trdf1['label'] == 1])\n",
    "        trdf1 = upsampled_tr\n",
    "\n",
    "    # shuffle only training dataset\n",
    "    trdf1 = trdf1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # convert to numpy\n",
    "    trdf1 = trdf1.to_numpy()\n",
    "    tedf1 = tedf1.to_numpy()\n",
    "\n",
    "    # posts and labels: data currently organised as (par_id | text | label)\n",
    "    trposts = [row[1] for row in trdf1]\n",
    "    trlabels = [row[2] for row in trdf1]\n",
    "    teposts = [row[1] for row in tedf1]\n",
    "    telabels = [row[2] for row in tedf1]\n",
    "\n",
    "    # perform encoding\n",
    "    encodings_trn = tokenizer(trposts, padding=PADDING, truncation=TRUNCATION)\n",
    "    encodings_tst = tokenizer(teposts, padding=PADDING, truncation=TRUNCATION)\n",
    "\n",
    "    # convert to Dataset\n",
    "    dataset_trn = PCLDataset(encodings_trn, trlabels)\n",
    "    dataset_tst = PCLDataset(encodings_tst, telabels)\n",
    "\n",
    "    print(\"Datasets loaded!\")\n",
    "\n",
    "    return dataset_trn, dataset_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_device():\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        device = \"cpu\"\n",
    "\n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassification: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prepared!\n",
      "Loading datasets...\n",
      "Datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model = prepare_model(MODEL, fast=FAST_TOKENIZER)\n",
    "dataset_trn, dataset_dev, dataset_tst = prep_dataset_from_csv(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaForSequenceClassification(\n",
       "  (deberta): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 768)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = prep_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/jk3120/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loader_trn = DataLoader(dataset_trn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loader_dev = DataLoader(dataset_dev, batch_size=BATCH_SIZE, shuffle=False)\n",
    "loader_tst = DataLoader(dataset_tst, batch_size=BATCH_SIZE, shuffle=False)\n",
    "optim = AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb125fccdbd4e4b8bc0e503f2c0f09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "Epoch 0\n",
      "Confusion Matrix\n",
      "[[1852   43]\n",
      " [ 123   76]]\n",
      "F1 Score\n",
      "0.4779874213836478\n",
      "Saving model...\n",
      "Model saved!\n",
      "Evaluating model...\n",
      "Epoch 1\n",
      "Confusion Matrix\n",
      "[[1877   18]\n",
      " [ 150   49]]\n",
      "F1 Score\n",
      "0.3684210526315789\n",
      "Saving model...\n",
      "Model saved!\n",
      "Evaluating model...\n",
      "Epoch 2\n",
      "Confusion Matrix\n",
      "[[1822   73]\n",
      " [ 100   99]]\n",
      "F1 Score\n",
      "0.5336927223719677\n",
      "Saving model...\n",
      "Model saved!\n",
      "Evaluating model...\n",
      "Epoch 3\n",
      "Confusion Matrix\n",
      "[[1854   41]\n",
      " [ 119   80]]\n",
      "F1 Score\n",
      "0.5\n",
      "Saving model...\n",
      "Model saved!\n",
      "Evaluating model...\n",
      "Epoch 4\n",
      "Confusion Matrix\n",
      "[[1862   33]\n",
      " [ 149   50]]\n",
      "F1 Score\n",
      "0.35460992907801414\n",
      "Saving model...\n",
      "Model saved!\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# progress bar\n",
    "num_training_steps = TRAIN_EPOCH * len(loader_trn)\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "# start training\n",
    "for epoch in range(TRAIN_EPOCH):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in loader_trn:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    ##### evaluating model #####\n",
    "    print(\"Evaluating model...\")\n",
    "    print(\"Epoch\", epoch)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_labels_full = []\n",
    "        true_labels_full = []\n",
    "        for batch in loader_dev:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = F.softmax(outputs.logits, dim=-1)\n",
    "            predictions = torch.argmax(predictions, dim=-1)\n",
    "\n",
    "            pred_labels = [i.item() for i in predictions]\n",
    "            true_labels = [i.item() for i in labels]\n",
    "            pred_labels_full.extend(pred_labels)\n",
    "            true_labels_full.extend(true_labels)\n",
    "        # print metrics\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(confusion_matrix(true_labels_full, pred_labels_full))\n",
    "        print(\"F1 Score\")\n",
    "        print(f1_score(true_labels_full, pred_labels_full))\n",
    "    \n",
    "    print('Saving model...')\n",
    "    model.save_pretrained(MODEL_SAVE_PATH + '.epoch-' + str(epoch))\n",
    "    tokenizer.save_pretrained(MODEL_SAVE_PATH + '.epoch-' + str(epoch))\n",
    "    print('Model saved!')\n",
    "\n",
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
